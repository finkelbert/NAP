%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Aviad Albert at 2021-10-11 13:22:49 +0300 


%% Saved with string encoding Unicode (UTF-8) 



@article{SchielzethForstmeier2009,
	Author = {Schielzeth, Holger and Forstmeier, Wolfgang},
	Doi = {10.1093/beheco/arn145},
	Issn = {1045-2249},
	Journaltitle = {Behavioral Ecology},
	Number = {2},
	Pages = {416--420},
	Pmid = {19461866},
	Title = {{Conclusions beyond support: {Overconfident} estimates in mixed models.}},
	Url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2657178\&tool=pmcentrez\&rendertype=abstract},
	Volume = {20},
	Year = {2009},
	Bdsk-Url-1 = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2657178%5C&tool=pmcentrez%5C&rendertype=abstract},
	Bdsk-Url-2 = {https://doi.org/10.1093/beheco/arn145}}

@article{chung2013weakly,
	Author = {Chung, Y and Gelman, Andrew and Rabe-Hesketh, S and Liu, J and Dorie, V},
	Journal = {Manuscript submitted for publication},
	Title = {Weakly Informative Prior for Point Estimation of Covariance Matrices in Hierarchical Models},
	Year = {2013}}

@article{gelman2008weakly,
	Author = {Gelman, Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung},
	Journal = {The Annals of Applied Statistics},
	Pages = {1360--1383},
	Publisher = {JSTOR},
	Title = {A weakly informative default prior distribution for logistic and other regression models},
	Year = {2008}}

@article{GelmanEtAl2017,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017Entrp..19..555G},
	Archiveprefix = {arXiv},
	Author = {{Gelman}, Andrew and {Simpson}, D. and {Betancourt}, M.},
	Date-Modified = {2021-10-11 13:22:48 +0300},
	Doi = {10.3390/e19100555},
	Eprint = {1708.07487},
	Journal = {Entropy},
	Month = oct,
	Pages = {555},
	Primaryclass = {stat.ME},
	Title = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
	Volume = 19,
	Year = 2017,
	Bdsk-Url-1 = {https://doi.org/10.3390/e19100555}}

@incollection{Jaynes1976,
	Address = {Dordrecht},
	Author = {Jaynes, E. T. and Kempthorne, Oscar},
	Booktitle = {Foundations of Probability Theory, Statistical Inference, and Statistical Theories of Science},
	Doi = {10.1007/978-94-010-1436-6_6},
	Editor = {Harper, William Leonard and Hooker, Clifford Alan},
	Isbn = {978-94-010-1436-6},
	Pages = {175--257},
	Publisher = {Springer Netherlands},
	Series = {The {University} of {Western Ontario} Series in Philosophy of Science},
	Title = {Confidence Intervals vs. {Bayesian} Intervals},
	Volume = {6b},
	Year = {1976},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-94-010-1436-6_6}}

@article{MoreyEtAl2015,
	Abstract = {Interval estimates -- estimates of parameters that include an allowance for sampling uncertainty -- have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 {\%}) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
	Author = {Morey, Richard D and Hoekstra, Rink and Rouder, Jeffrey N and Lee, Michael D and Wagenmakers, Eric-Jan},
	Doi = {10.3758/s13423-015-0947-8},
	Issn = {1531-5320},
	Number = {1},
	Pages = {103--123},
	Title = {The Fallacy of Placing Confidence in Confidence Intervals},
	Url = {http://dx.doi.org/10.3758/s13423-015-0947-8},
	Volume = {23},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.3758/s13423-015-0947-8}}

@misc{Stan2018,
	Author = {{Stan Development Team}},
	Title = {Stan: {A C++} Library for Probability and Sampling, Version 2.18.2},
	Url = {http://mc-stan.org/},
	Year = {2018},
	Bdsk-Url-1 = {http://mc-stan.org/}}

@report{burknerModelingMonotonicEffects2018,
	Abstract = {Ordinal predictors are commonly used in regression models. They are often incorrectly treated as either nominal or metric, thus under- or overestimating the contained information. Such practices may lead to worse inference and predictions compared to methods which are specifically designed for this purpose. We propose a new method for modeling ordinal predictors that applies in situations in which it is reasonable to assume their effects to be monotonic. The parameterization of such monotonic effects is realized in terms of a scale parameter \$b\$ representing the direction and size of the effect and a simplex parameter \$\textbackslash{}zeta\$ modeling the normalized differences between categories. This ensures that predictions increase or decrease monotonically, while changes between adjacent categories may vary across categories. This formulation generalizes to interaction terms as well as multilevel structures. Monotonic effects may not only be applied to ordinal predictors, but also to other discrete variables for which a monotonic relationship is plausible. In simulation studies, we show that the model is well calibrated and, in case of monotonicity, has similar or even better predictive performance than other approaches designed to handle ordinal predictors. Using Stan, we developed a Bayesian estimation method for monotonic effects, which allows to incorporate prior information and to check the assumption of monotonicity. We have implemented this method in the R package brms, so that fitting monotonic effects in a fully Bayesian framework is now straightforward.},
	Author = {B{\"u}rkner, {Paul-Christian} and Charpentier, Emmanuel},
	Date = {2018-11-02},
	Doi = {10.31234/osf.io/9qkhj},
	File = {/home/bruno/ownCloud/bib_papers/VehtariB{\"u}rkner_Charpentier_2018_Modeling Monotonic Effects of Ordinal Predictors in Bayesian Regression Models.pdf;/home/bruno/Zotero/storage/VE2KRSKN/B{\"u}rkner and Charpentier - 2018 - Modeling Monotonic Effects of Ordinal Predictors i.pdf},
	Institution = {{PsyArXiv}},
	Title = {Modeling monotonic Effects of Ordinal Predictors in {Bayesian} Regression Models},
	Type = {preprint},
	Url = {https://osf.io/9qkhj},
	Urldate = {2019-10-08},
	Bdsk-Url-1 = {https://osf.io/9qkhj},
	Bdsk-Url-2 = {https://doi.org/10.31234/osf.io/9qkhj}}

@article{NicenboimVasishth2016,
	Author = {Bruno Nicenboim and Shravan Vasishth},
	Doi = {10.1111/lnc3.12207},
	Eprint = {https://arxiv.org/abs/1602.00245},
	Issn = {1749-818X},
	Journal = {Language and Linguistics Compass},
	Number = {11},
	Pages = {591--613},
	Title = {{Statistical methods for linguistic research: {Foundational} Ideas - {Part} {II}}},
	Url = {http://dx.doi.org/10.1111/lnc3.12207},
	Volume = {10},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/lnc3.12207}}

@article{vehtariPracticalBayesianModel2017,
	Abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
	Author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	Date = {2017-09},
	Doi = {10.1007/s11222-016-9696-4},
	File = {/home/bruno/ownCloud/bib_papers/Vehtari et al_2017_Practical Bayesian model evaluation using leave-one-out cross-validation and.pdf},
	Issn = {0960-3174, 1573-1375},
	Journaltitle = {Statistics and Computing},
	Langid = {english},
	Number = {5},
	Pages = {1413-1432},
	Title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
	Url = {http://link.springer.com/10.1007/s11222-016-9696-4},
	Urldate = {2019-05-17},
	Volume = {27},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/s11222-016-9696-4},
	Bdsk-Url-2 = {https://doi.org/10.1007/s11222-016-9696-4}}

@article{vehtariParetoSmoothedImportance2015,
	Abstract = {Importance weighting is a convenient general way to adjust for draws from the wrong distribution, but the resulting ratio estimate can be noisy when the importance weights have a heavy right tail, as routinely occurs when there are aspects of the target distribution not well captured by the approximating distribution. More stable estimates can be obtained by truncating the importance ratios. Here we present a new method for stabilizing importance weights using a generalized Pareto distribution fit to the upper tail of the distribution of the simulated importance ratios. The method includes stabilized effective sample estimates, Monte Carlo error estimates and convergence diagnostics.},
	Annotation = {Comment: Major revision: more simulation studies; effective sample size, Monte Carlo error and convergence rate estimates},
	Archiveprefix = {arXiv},
	Author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	Date = {2015-07-09},
	Eprint = {1507.02646},
	Eprinttype = {arxiv},
	File = {/home/bruno/ownCloud/bib_papers/Vehtari et al_2015_Pareto Smoothed Importance Sampling.pdf},
	Keywords = {Statistics - Methodology,Statistics - Computation},
	Langid = {english},
	Primaryclass = {stat},
	Title = {Pareto {{Smoothed Importance Sampling}}},
	Url = {http://arxiv.org/abs/1507.02646},
	Urldate = {2019-05-17},
	Bdsk-Url-1 = {http://arxiv.org/abs/1507.02646}}

@article{shiffrinSurveyModelEvaluation2008,
	Abstract = {This article reviews current methods for evaluating models in the cognitive sciences, including theoretically based approaches, such as Bayes factors and minimum description length measures; simulation approaches, including model mimicry evaluations; and practical approaches, such as validation and generalization measures. This article argues that, although often useful in specific settings, most of these approaches are limited in their ability to give a general assessment of models. This article argues that hierarchical methods, generally, and hierarchical Bayesian methods, specifically, can provide a more thorough evaluation of models in the cognitive sciences. This article presents two worked examples of hierarchical Bayesian analyses to demonstrate how the approach addresses key questions of descriptive adequacy, parameter interference, prediction, and generalization in principled and coherent ways.},
	Author = {Shiffrin, Richard and Lee, Michael and Kim, Woojae and Wagenmakers, Eric-Jan},
	Date = {2008-12},
	Doi = {10.1080/03640210802414826},
	File = {/home/bruno/ownCloud/bib_papers/Shiffrin et al_2008_A Survey of Model Evaluation Approaches With a Tutorial on Hierarchical.pdf},
	Issn = {0364-0213},
	Journaltitle = {Cognitive Science: A Multidisciplinary Journal},
	Langid = {english},
	Number = {8},
	Pages = {1248-1284},
	Title = {A {{Survey}} of {{Model Evaluation Approaches With}} a {{Tutorial}} on {{Hierarchical Bayesian Methods}}},
	Url = {http://doi.wiley.com/10.1080/03640210802414826},
	Urldate = {2019-05-17},
	Volume = {32},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1080/03640210802414826},
	Bdsk-Url-2 = {https://doi.org/10.1080/03640210802414826}}

@book{gelmanBayesianDataAnalysis2013,
	Abstract = {Winner of the 2016 De Groot Prize from the International Society for Bayesian AnalysisNow in its third edition, this classic book is widely considered the},
	Author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B. and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	Date = {2013-11-27},
	Doi = {10.1201/b16018},
	File = {/home/bruno/Zotero/storage/SWDWNDQ7/9780429113079.html},
	Isbn = {978-0-429-11307-9},
	Langid = {english},
	Publisher = {{Chapman and Hall/CRC}},
	Title = {Bayesian {{Data Analysis}}},
	Url = {https://www.taylorfrancis.com/books/9780429113079},
	Urldate = {2019-08-27},
	Bdsk-Url-1 = {https://www.taylorfrancis.com/books/9780429113079},
	Bdsk-Url-2 = {https://doi.org/10.1201/b16018}}

@article{VasishthEtAl2017EDAPS,
	Author = {Shravan Vasishth and Bruno Nicenboim and Mary E. Beckman and Fangfang Li and Eunjong Kong},
	Doi = {10.1016/j.wocn.2018.07.008},
	Eprint = {https://osf.io/5pj49/},
	Journal = {Journal of Phonetics},
	Pages = {147--161},
	Title = {Bayesian data analysis in the phonetic sciences: {A} tutorial introduction},
	Volume = {71},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.wocn.2018.07.008}}
